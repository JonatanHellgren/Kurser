{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ranking and selecting features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "In this example, we'll exemplify some of scikit-learn's ranking functions used to score the importance of features. We'll reuse the running example, the Adult dataset that we used in the first exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'datasets/adult.names'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-6b9efbe17235>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mcol_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol_types\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'datasets/adult.names'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0mXtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'datasets/adult.data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-6b9efbe17235>\u001b[0m in \u001b[0;36mread_names\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtypes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'|'\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m':'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'datasets/adult.names'"
     ]
    }
   ],
   "source": [
    "def read_names(filename):\n",
    "    names = []\n",
    "    types = []\n",
    "    with open(filename) as f:\n",
    "        for l in f:\n",
    "            if l[0] == '|' or ':' not in l:\n",
    "                continue\n",
    "            cols = l.split(':')\n",
    "            names.append(cols[0])\n",
    "            if cols[1].startswith(' continuous.'):\n",
    "                types.append(float)\n",
    "            else:\n",
    "                types.append(str)\n",
    "    return names, types\n",
    "\n",
    "def read_data(filename, col_names, col_types):\n",
    "    X = []\n",
    "    Y = []\n",
    "    with open(filename) as f:\n",
    "        for l in f:\n",
    "            cols = l.strip('\\n.').split(', ')\n",
    "            if len(cols) < len(col_names):\n",
    "                continue\n",
    "            X.append( { n:t(c) for n, t, c in zip(col_names, col_types, cols) } )\n",
    "            Y.append(cols[-1])\n",
    "    return X, Y\n",
    "\n",
    "col_names, col_types = read_names('datasets/adult.names')\n",
    "\n",
    "Xtrain, Ytrain = read_data('datasets/adult.data', col_names, col_types)\n",
    "Xtest, Ytest = read_data('datasets/adult.test', col_names, col_types)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you might recall, the instances in this dataset consist of several features describing each individual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'age': 39.0,\n",
       " 'capital-gain': 2174.0,\n",
       " 'capital-loss': 0.0,\n",
       " 'education': 'Bachelors',\n",
       " 'education-num': 13.0,\n",
       " 'fnlwgt': 77516.0,\n",
       " 'hours-per-week': 40.0,\n",
       " 'marital-status': 'Never-married',\n",
       " 'native-country': 'United-States',\n",
       " 'occupation': 'Adm-clerical',\n",
       " 'race': 'White',\n",
       " 'relationship': 'Not-in-family',\n",
       " 'sex': 'Male',\n",
       " 'workclass': 'State-gov'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We first convert the training set into numerical vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "dv = DictVectorizer()\n",
    "dv.fit(Xtrain)\n",
    "\n",
    "X_vec = dv.transform(Xtrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first scoring function we'll investigate is called the [mutual information](https://en.wikipedia.org/wiki/Mutual_information). [Here](http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.mutual_info_classif.html) is the description from scikit-learn about how this scoring function works.\n",
    "\n",
    "(To see the formula used to compute the mutual information score, see the [description](https://nlp.stanford.edu/IR-book/html/htmledition/mutual-information-1.html) in the book *Introduction to Information Retrieval* by Manning and SchÃ¼tze.)\n",
    "\n",
    "We apply the scoring function to all the features, and we then print the top 10 high-scoring features. Please refer back to the perceptron example in the previous lecture for an explanation about the step where we sort the features by importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fnlwgt 0.393714477479\n",
      "marital-status=Married-civ-spouse 0.105432234254\n",
      "capital-gain 0.0833823721234\n",
      "relationship=Husband 0.0808768411074\n",
      "age 0.0687725396789\n",
      "education-num 0.0648722276268\n",
      "marital-status=Never-married 0.0619507241042\n",
      "hours-per-week 0.0422833222022\n",
      "relationship=Own-child 0.0382161042027\n",
      "capital-loss 0.0369804845104\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "feature_scores = mutual_info_classif(X_vec, Ytrain)\n",
    "\n",
    "for score, fname in sorted(zip(feature_scores, dv.get_feature_names()), reverse=True)[:10]:\n",
    "    print(fname, score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second scoring function uses the so-called $F$-statistic in an [ANOVA test](https://en.wikipedia.org/wiki/Analysis_of_variance).\n",
    "\n",
    "As you can see, there is an overlap between the top-10 list produced by this scorer and the previous list, but they are not identical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "marital-status=Married-civ-spouse 8025.84206159\n",
      "relationship=Husband 6240.01827621\n",
      "education-num 4120.09577971\n",
      "marital-status=Never-married 3674.20014657\n",
      "age 1886.70731372\n",
      "hours-per-week 1813.38628222\n",
      "relationship=Own-child 1794.15748936\n",
      "capital-gain 1709.15006374\n",
      "sex=Female 1593.10790745\n",
      "sex=Male 1593.10790745\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import f_classif\n",
    "\n",
    "feature_scores = f_classif(X_vec, Ytrain)[0]\n",
    "\n",
    "for score, fname in sorted(zip(feature_scores, dv.get_feature_names()), reverse=True)[:10]:\n",
    "    print(fname, score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yet another feature scoring function. It is based on the well-known [$\\chi^2$ statistical test](https://en.wikipedia.org/wiki/Chi-squared_test)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "capital-gain 82192467.1415\n",
      "capital-loss 1372145.8902\n",
      "fnlwgt 171147.682865\n",
      "age 8600.61182156\n",
      "hours-per-week 6476.40899593\n",
      "marital-status=Married-civ-spouse 3477.51587745\n",
      "relationship=Husband 3114.94154603\n",
      "education-num 2401.4217772\n",
      "marital-status=Never-married 2218.52197657\n",
      "relationship=Own-child 1435.87301604\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "feature_scores = chi2(X_vec, Ytrain)[0]\n",
    "\n",
    "for score, fname in sorted(zip(feature_scores, dv.get_feature_names()), reverse=True)[:10]:\n",
    "    print(fname, score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In practice when we'd like to use feature selection in scikit-learn, we just plug a selector into our pipeline. `SelectKBest` and `SelectPercentile` are the most common selectors. They use a feature scoring function (such as the ones above) to rank the features; by default, the `f_classif` scoring function is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, SelectPercentile\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "pipeline = make_pipeline(\n",
    "        DictVectorizer(),\n",
    "        SelectKBest(k=100), # or SelectPercentile(...)\n",
    "        DecisionTreeClassifier()\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
